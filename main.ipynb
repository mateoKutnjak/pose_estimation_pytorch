{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/mateoKutnjak/pose_estimation_pytorch.git\n",
    "\n",
    "import sys\n",
    "sys.path.append('/content/pose_estimation_pytorch')\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.rmsprop import RMSprop\n",
    "from torch.optim.adam import Adam\n",
    "import argparse\n",
    "\n",
    "import models\n",
    "import datasets\n",
    "import losses\n",
    "import eval\n",
    "import util_plot\n",
    "import loggers\n",
    "\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_IMAGES_DIR = '/content/drive/My Drive/_images'\n",
    "_ANNOTATIONS_JSON_FILE = '/content/drive/My Drive/_annotations/annotations.json'\n",
    "IMAGES_DIR = '/content/drive/My Drive/images'\n",
    "ANNOTATIONS_JSON_FILE = '/content/drive/My Drive/annotations/annotations.json'\n",
    "MEAN_PATH = '/content/drive/My Drive/pose_estimation/mean_total.npy'\n",
    "STD_PATH = '/content/drive/My Drive/pose_estimation/std_total.npy'\n",
    "LOGGER_CSV_PATH = '/content/drive/My Drive/pose_estimation/logger.csv'\n",
    "SAVED_MODEL = '/content/drive/My Drive/pose_estimation/checkpoint.pth'\n",
    "\n",
    "\n",
    "args_dict = {\n",
    "    'device': 'gpu', \n",
    "    \n",
    "    'lr': 0.00025, \n",
    "    'batch_size': 8, \n",
    "    'input_dim': 256, \n",
    "    'output_dim': 64, \n",
    "    'epochs': 100, \n",
    "    'stacks': 2, \n",
    "    'channels': 256, \n",
    "    'joints': 16, \n",
    "    \n",
    "    'threshold': 0.5, \n",
    "    \n",
    "    'images_dir': IMAGES_DIR, \n",
    "    'annots_path': ANNOTATIONS_JSON_FILE, \n",
    "    'mean_path': MEAN_PATH, \n",
    "    'std_path': STD_PATH, \n",
    "    'logger_csv_path': LOGGER_CSV_PATH, \n",
    "    'saved_model': SAVED_MODEL\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args_dict['saved_model'] is not None and os.path.exists(args_dict['saved_model']):\n",
    "    device, model, optimizer, saved_args_dict = models.load_model(args_dict['saved_model'])\n",
    "    args_dict = saved_args_dict\n",
    "else:\n",
    "    model = models.HourglassNetwork(\n",
    "        num_channels=args.channels,\n",
    "        num_stacks=args.stacks,\n",
    "        num_classes=args.joints,\n",
    "        input_shape=(args.input_dim, args.input_dim, 3)\n",
    "    )\n",
    "    device = torch.device(args_dict['device'])\n",
    "    model = torch.nn.DataParallel(model).to(device).double()\n",
    "    optimizer = Adam(model.parameters(), lr=args.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpii_train = datasets.MPII_dataset(\n",
    "        dataset_type='train',\n",
    "        images_dir=args_dict['images_dir'],\n",
    "        annots_json_filename=args_dict['annots_path'],\n",
    "        mean_path=args_dict['mean_path'],\n",
    "        std_path=args_dict['std_path'],\n",
    "        input_shape=args_dict['input_dim'],\n",
    "        output_shape=args_dict['output_dim']\n",
    "    )\n",
    "\n",
    "mpii_valid = datasets.MPII_dataset(\n",
    "    dataset_type='valid',\n",
    "    images_dir=args_dict['images_dir'],\n",
    "    annots_json_filename=args_dict['annots_path'],\n",
    "    mean_path=args_dict['mean_path'],\n",
    "    std_path=args_dict['std_path'],\n",
    "    input_shape=args_dict['input_dim'],\n",
    "    output_shape=args_dict['output_dim']\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(dataset=mpii_train, batch_size=args_dict['batch_size'], shuffle=True, num_workers=0)\n",
    "valid_dataloader = DataLoader(dataset=mpii_valid, batch_size=args_dict['batch_size'], shuffle=False, num_workers=0)\n",
    "\n",
    "criterion = losses.JointsMSELoss().to(device)\n",
    "logger = loggers.CSVLogger(args_dict['logger_csv_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    for epoch in range(args_dict.get('epoch_to_start', 0), args_dict['epochs']):\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        for i, (input_batch, output_batch, meta_batch) in enumerate(train_dataloader):\n",
    "\n",
    "            # TODO adjust learning rate\n",
    "\n",
    "            x = input_batch.to(device)\n",
    "            y_kappa = output_batch.to(device, non_blocking=True)\n",
    "            weights = meta_batch['label_weights'].to(device, non_blocking=True)\n",
    "\n",
    "            y = model(x)\n",
    "\n",
    "            loss = 0\n",
    "            for _y in y:\n",
    "                loss += criterion(_y, y_kappa, weights)\n",
    "\n",
    "            joint_distances, accuracy_per_joint, average_accuracy = eval.output_accuracy(\n",
    "                y=y[-1],\n",
    "                y_kappa=y_kappa,\n",
    "                threshold=args_dict['threshold']\n",
    "            )\n",
    "\n",
    "            print('TRAIN: Epoch=[{}/{}], Step=[{}/{}], Loss={:.8f}, Avg_Acc: {:.5f}'\n",
    "                  .format(epoch + 1, args_dict['epochs'], i + 1, len(train_dataloader), loss.item(), average_accuracy))\n",
    "\n",
    "            logger.log(epoch+1, args_dict['epochs'], i, len(train_dataloader), 'train', loss, accuracy_per_joint, average_accuracy)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for i, (input_batch, output_batch, meta_batch) in enumerate(valid_dataloader):\n",
    "                x = input_batch.to(device)\n",
    "                y_kappa = output_batch.to(device, non_blocking=True)\n",
    "                weights = meta_batch['label_weights'].to(device, non_blocking=True)\n",
    "\n",
    "                y = model(x)\n",
    "\n",
    "                loss = 0\n",
    "                for _y in y:\n",
    "                    loss += criterion(_y, y_kappa, weights)\n",
    "\n",
    "                joint_distances, accuracy_per_joint, average_accuracy = eval.output_accuracy(\n",
    "                    y=y[-1],\n",
    "                    y_kappa=y_kappa,\n",
    "                    threshold=args_dict['threshold']\n",
    "                )\n",
    "\n",
    "                print('VALID: Epoch=[{}/{}], Step=[{}/{}], Loss={:.8f}, Avg_Acc: {:.5f}'\n",
    "                      .format(epoch + 1, args_dict['epochs'], i + 1, len(valid_dataloader), loss.item(),\n",
    "                              average_accuracy))\n",
    "\n",
    "                logger.log(epoch+1, args_dict['epochs'], i, len(train_dataloader), 'valid', loss, accuracy_per_joint, average_accuracy)\n",
    "\n",
    "        args_dict['epoch_to_start'] = epoch+1\n",
    "\n",
    "        models.save_model(\n",
    "            model=model,\n",
    "            optimizer=optimizer,\n",
    "            args_dict=args_dict\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
