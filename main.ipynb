{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwmSQ5T-eWnU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "outputId": "4ec71793-7be1-41fc-bdab-1675c9bf53f7"
      },
      "source": [
        "!git clone https://github.com/mateoKutnjak/pose_estimation_pytorch.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pose_estimation_pytorch'...\n",
            "remote: Enumerating objects: 48, done.\u001b[K\n",
            "remote: Counting objects: 100% (48/48), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 48 (delta 22), reused 43 (delta 17), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (48/48), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEkYgB4LeZnz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/pose_estimation_pytorch/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eB2My8NzTR3X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        },
        "outputId": "8d39ef6c-bc74-4db2-a965-23f7fe9fbe00"
      },
      "source": [
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim.rmsprop import RMSprop\n",
        "from torch.optim.adam import Adam\n",
        "import argparse\n",
        "\n",
        "import models\n",
        "import datasets\n",
        "import losses\n",
        "import eval\n",
        "import util_plot\n",
        "import loggers\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgG8qwtYTR3d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_IMAGES_DIR = '/content/drive/My Drive/_images'\n",
        "_ANNOTATIONS_JSON_FILE = '/content/drive/My Drive/_annotations/annotations.json'\n",
        "IMAGES_DIR = '/content/drive/My Drive/images'\n",
        "ANNOTATIONS_JSON_FILE = '/content/pose_estimation_pytorch/annotations.json'\n",
        "MEAN_PATH = '/content/drive/My Drive/pose_estimation/mean_total.npy'\n",
        "STD_PATH = '/content/drive/My Drive/pose_estimation/std_total.npy'\n",
        "LOGGER_CSV_PATH = '/content/drive/My Drive/pose_estimation/logger.csv'\n",
        "SAVED_MODEL = '/content/drive/My Drive/pose_estimation/checkpoint.pth'\n",
        "\n",
        "\n",
        "args_dict = {\n",
        "    'device': 'cuda', \n",
        "    \n",
        "    'lr': 0.00025, \n",
        "    'batch_size': 8, \n",
        "    'input_dim': 256, \n",
        "    'output_dim': 64, \n",
        "    'epochs': 100, \n",
        "    'stacks': 2, \n",
        "    'channels': 256, \n",
        "    'joints': 16, \n",
        "    \n",
        "    'threshold': 0.5, \n",
        "    \n",
        "    'images_dir': IMAGES_DIR, \n",
        "    'annots_path': ANNOTATIONS_JSON_FILE, \n",
        "    'mean_path': MEAN_PATH, \n",
        "    'std_path': STD_PATH, \n",
        "    'logger_csv_path': LOGGER_CSV_PATH, \n",
        "    'saved_model': SAVED_MODEL\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_9RhADNTR3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if args_dict['saved_model'] is not None and os.path.exists(args_dict['saved_model']):\n",
        "    device, model, optimizer, saved_args_dict = models.load_model(args_dict['saved_model'])\n",
        "    args_dict = saved_args_dict\n",
        "else:\n",
        "    model = models.HourglassNetwork(\n",
        "        num_channels=args_dict['channels'],\n",
        "        num_stacks=args_dict['stacks'],\n",
        "        num_classes=args_dict['joints'],\n",
        "        input_shape=(args_dict['input_dim'], args_dict['input_dim'], 3)\n",
        "    )\n",
        "    device = torch.device(args_dict['device'])\n",
        "    model = torch.nn.DataParallel(model).to(device).double()\n",
        "    optimizer = Adam(model.parameters(), lr=args_dict['lr'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1DD9528TR3l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "0588417c-268a-4d8e-8e76-8cb522cbdb32"
      },
      "source": [
        "mpii_train = datasets.MPII_dataset(\n",
        "        dataset_type='train',\n",
        "        images_dir=args_dict['images_dir'],\n",
        "        annots_json_filename=args_dict['annots_path'],\n",
        "        mean_path=args_dict['mean_path'],\n",
        "        std_path=args_dict['std_path'],\n",
        "        input_shape=args_dict['input_dim'],\n",
        "        output_shape=args_dict['output_dim']\n",
        "    )\n",
        "\n",
        "mpii_valid = datasets.MPII_dataset(\n",
        "    dataset_type='valid',\n",
        "    images_dir=args_dict['images_dir'],\n",
        "    annots_json_filename=args_dict['annots_path'],\n",
        "    mean_path=args_dict['mean_path'],\n",
        "    std_path=args_dict['std_path'],\n",
        "    input_shape=args_dict['input_dim'],\n",
        "    output_shape=args_dict['output_dim']\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(dataset=mpii_train, batch_size=args_dict['batch_size'], shuffle=True, num_workers=0)\n",
        "valid_dataloader = DataLoader(dataset=mpii_valid, batch_size=args_dict['batch_size'], shuffle=False, num_workers=0)\n",
        "\n",
        "criterion = losses.JointsMSELoss().to(device)\n",
        "logger = loggers.CSVLogger(args_dict['logger_csv_path'])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train dataset mean and std information found\n",
            "Mean = [118.84298213 113.28508129 103.7345996 ]\n",
            "Std = [60.32564024 59.32674718 58.39673706]\n",
            "Train dataset mean and std information found\n",
            "Mean = [118.84298213 113.28508129 103.7345996 ]\n",
            "Std = [60.32564024 59.32674718 58.39673706]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRCWJ6O_TR3o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1326
        },
        "outputId": "f548b24d-e0d9-4697-cb48-3d6c2236dabd"
      },
      "source": [
        "    for epoch in range(args_dict.get('epoch_to_start', 0), args_dict['epochs']):\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        for i, (input_batch, output_batch, meta_batch) in enumerate(train_dataloader):\n",
        "\n",
        "            # TODO adjust learning rate\n",
        "\n",
        "            x = input_batch.to(device)\n",
        "            y_kappa = output_batch.to(device, non_blocking=True)\n",
        "            weights = meta_batch['label_weights'].to(device, non_blocking=True)\n",
        "\n",
        "            y = model(x)\n",
        "\n",
        "            loss = 0\n",
        "            for _y in y:\n",
        "                loss += criterion(_y, y_kappa, weights)\n",
        "\n",
        "            joint_distances, accuracy_per_joint, average_accuracy = eval.output_accuracy(\n",
        "                y=y[-1],\n",
        "                y_kappa=y_kappa,\n",
        "                threshold=args_dict['threshold']\n",
        "            )\n",
        "\n",
        "            print('TRAIN: Epoch=[{}/{}], Step=[{}/{}], Loss={:.8f}, Avg_Acc: {:.5f}'\n",
        "                  .format(epoch + 1, args_dict['epochs'], i + 1, len(train_dataloader), loss.item(), average_accuracy))\n",
        "\n",
        "            logger.log(epoch+1, args_dict['epochs'], i, len(train_dataloader), 'train', loss, accuracy_per_joint, average_accuracy)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            for i, (input_batch, output_batch, meta_batch) in enumerate(valid_dataloader):\n",
        "                x = input_batch.to(device)\n",
        "                y_kappa = output_batch.to(device, non_blocking=True)\n",
        "                weights = meta_batch['label_weights'].to(device, non_blocking=True)\n",
        "\n",
        "                y = model(x)\n",
        "\n",
        "                loss = 0\n",
        "                for _y in y:\n",
        "                    loss += criterion(_y, y_kappa, weights)\n",
        "\n",
        "                joint_distances, accuracy_per_joint, average_accuracy = eval.output_accuracy(\n",
        "                    y=y[-1],\n",
        "                    y_kappa=y_kappa,\n",
        "                    threshold=args_dict['threshold']\n",
        "                )\n",
        "\n",
        "                print('VALID: Epoch=[{}/{}], Step=[{}/{}], Loss={:.8f}, Avg_Acc: {:.5f}'\n",
        "                      .format(epoch + 1, args_dict['epochs'], i + 1, len(valid_dataloader), loss.item(),\n",
        "                              average_accuracy))\n",
        "\n",
        "                logger.log(epoch+1, args_dict['epochs'], i, len(train_dataloader), 'valid', loss, accuracy_per_joint, average_accuracy)\n",
        "\n",
        "        args_dict['epoch_to_start'] = epoch+1\n",
        "\n",
        "        models.save_model(\n",
        "            model=model,\n",
        "            optimizer=optimizer,\n",
        "            args_dict=args_dict\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN: Epoch=[1/100], Step=[1/2781], Loss=0.04099230, Avg_Acc: 0.01562\n",
            "TRAIN: Epoch=[1/100], Step=[2/2781], Loss=0.03181084, Avg_Acc: 0.03125\n",
            "TRAIN: Epoch=[1/100], Step=[3/2781], Loss=0.02106292, Avg_Acc: 0.00000\n",
            "TRAIN: Epoch=[1/100], Step=[4/2781], Loss=0.01978947, Avg_Acc: 0.00000\n",
            "TRAIN: Epoch=[1/100], Step=[5/2781], Loss=0.01603642, Avg_Acc: 0.03125\n",
            "TRAIN: Epoch=[1/100], Step=[6/2781], Loss=0.01461723, Avg_Acc: 0.03125\n",
            "TRAIN: Epoch=[1/100], Step=[7/2781], Loss=0.01305991, Avg_Acc: 0.02344\n",
            "TRAIN: Epoch=[1/100], Step=[8/2781], Loss=0.01039232, Avg_Acc: 0.01562\n",
            "TRAIN: Epoch=[1/100], Step=[9/2781], Loss=0.00959568, Avg_Acc: 0.00781\n",
            "TRAIN: Epoch=[1/100], Step=[10/2781], Loss=0.00948768, Avg_Acc: 0.01562\n",
            "TRAIN: Epoch=[1/100], Step=[11/2781], Loss=0.00679757, Avg_Acc: 0.01562\n",
            "TRAIN: Epoch=[1/100], Step=[12/2781], Loss=0.00623928, Avg_Acc: 0.02344\n",
            "TRAIN: Epoch=[1/100], Step=[13/2781], Loss=0.00583253, Avg_Acc: 0.04688\n",
            "TRAIN: Epoch=[1/100], Step=[14/2781], Loss=0.00434230, Avg_Acc: 0.05469\n",
            "TRAIN: Epoch=[1/100], Step=[15/2781], Loss=0.00412319, Avg_Acc: 0.00000\n",
            "TRAIN: Epoch=[1/100], Step=[16/2781], Loss=0.00404991, Avg_Acc: 0.02344\n",
            "TRAIN: Epoch=[1/100], Step=[17/2781], Loss=0.00406189, Avg_Acc: 0.02344\n",
            "TRAIN: Epoch=[1/100], Step=[18/2781], Loss=0.00317969, Avg_Acc: 0.02344\n",
            "TRAIN: Epoch=[1/100], Step=[19/2781], Loss=0.00250498, Avg_Acc: 0.02344\n",
            "TRAIN: Epoch=[1/100], Step=[20/2781], Loss=0.00320572, Avg_Acc: 0.04688\n",
            "TRAIN: Epoch=[1/100], Step=[21/2781], Loss=0.00212509, Avg_Acc: 0.01562\n",
            "TRAIN: Epoch=[1/100], Step=[22/2781], Loss=0.00258668, Avg_Acc: 0.01562\n",
            "TRAIN: Epoch=[1/100], Step=[23/2781], Loss=0.00228304, Avg_Acc: 0.00000\n",
            "TRAIN: Epoch=[1/100], Step=[24/2781], Loss=0.00167501, Avg_Acc: 0.00781\n",
            "TRAIN: Epoch=[1/100], Step=[25/2781], Loss=0.00217733, Avg_Acc: 0.03125\n",
            "TRAIN: Epoch=[1/100], Step=[26/2781], Loss=0.00171719, Avg_Acc: 0.00781\n",
            "TRAIN: Epoch=[1/100], Step=[27/2781], Loss=0.00174888, Avg_Acc: 0.02344\n",
            "TRAIN: Epoch=[1/100], Step=[28/2781], Loss=0.00121859, Avg_Acc: 0.03906\n",
            "TRAIN: Epoch=[1/100], Step=[29/2781], Loss=0.00152617, Avg_Acc: 0.03906\n",
            "TRAIN: Epoch=[1/100], Step=[30/2781], Loss=0.00138635, Avg_Acc: 0.02344\n",
            "TRAIN: Epoch=[1/100], Step=[31/2781], Loss=0.00138260, Avg_Acc: 0.02344\n",
            "TRAIN: Epoch=[1/100], Step=[32/2781], Loss=0.00118160, Avg_Acc: 0.03906\n",
            "TRAIN: Epoch=[1/100], Step=[33/2781], Loss=0.00124040, Avg_Acc: 0.01562\n",
            "TRAIN: Epoch=[1/100], Step=[34/2781], Loss=0.00116981, Avg_Acc: 0.01562\n",
            "TRAIN: Epoch=[1/100], Step=[35/2781], Loss=0.00112387, Avg_Acc: 0.02344\n",
            "TRAIN: Epoch=[1/100], Step=[36/2781], Loss=0.00136564, Avg_Acc: 0.01562\n",
            "TRAIN: Epoch=[1/100], Step=[37/2781], Loss=0.00131780, Avg_Acc: 0.02344\n",
            "TRAIN: Epoch=[1/100], Step=[38/2781], Loss=0.00122504, Avg_Acc: 0.02344\n",
            "TRAIN: Epoch=[1/100], Step=[39/2781], Loss=0.00108334, Avg_Acc: 0.01562\n",
            "TRAIN: Epoch=[1/100], Step=[40/2781], Loss=0.00118941, Avg_Acc: 0.01562\n",
            "TRAIN: Epoch=[1/100], Step=[41/2781], Loss=0.00121520, Avg_Acc: 0.02344\n",
            "TRAIN: Epoch=[1/100], Step=[42/2781], Loss=0.00110445, Avg_Acc: 0.01562\n",
            "TRAIN: Epoch=[1/100], Step=[43/2781], Loss=0.00088943, Avg_Acc: 0.00781\n",
            "TRAIN: Epoch=[1/100], Step=[44/2781], Loss=0.00088461, Avg_Acc: 0.01562\n",
            "TRAIN: Epoch=[1/100], Step=[45/2781], Loss=0.00091843, Avg_Acc: 0.02344\n",
            "TRAIN: Epoch=[1/100], Step=[46/2781], Loss=0.00093661, Avg_Acc: 0.00000\n",
            "TRAIN: Epoch=[1/100], Step=[47/2781], Loss=0.00079520, Avg_Acc: 0.03125\n",
            "TRAIN: Epoch=[1/100], Step=[48/2781], Loss=0.00116792, Avg_Acc: 0.04688\n",
            "TRAIN: Epoch=[1/100], Step=[49/2781], Loss=0.00097943, Avg_Acc: 0.01562\n",
            "TRAIN: Epoch=[1/100], Step=[50/2781], Loss=0.00088945, Avg_Acc: 0.05469\n",
            "TRAIN: Epoch=[1/100], Step=[51/2781], Loss=0.00095061, Avg_Acc: 0.00781\n",
            "TRAIN: Epoch=[1/100], Step=[52/2781], Loss=0.00086655, Avg_Acc: 0.00000\n",
            "TRAIN: Epoch=[1/100], Step=[53/2781], Loss=0.00089062, Avg_Acc: 0.01562\n",
            "TRAIN: Epoch=[1/100], Step=[54/2781], Loss=0.00079990, Avg_Acc: 0.03906\n",
            "TRAIN: Epoch=[1/100], Step=[55/2781], Loss=0.00097441, Avg_Acc: 0.00781\n",
            "TRAIN: Epoch=[1/100], Step=[56/2781], Loss=0.00099868, Avg_Acc: 0.00781\n",
            "TRAIN: Epoch=[1/100], Step=[57/2781], Loss=0.00092142, Avg_Acc: 0.00781\n",
            "TRAIN: Epoch=[1/100], Step=[58/2781], Loss=0.00078467, Avg_Acc: 0.02344\n",
            "TRAIN: Epoch=[1/100], Step=[59/2781], Loss=0.00111597, Avg_Acc: 0.02344\n",
            "TRAIN: Epoch=[1/100], Step=[60/2781], Loss=0.00091763, Avg_Acc: 0.03125\n",
            "TRAIN: Epoch=[1/100], Step=[61/2781], Loss=0.00090137, Avg_Acc: 0.03125\n",
            "TRAIN: Epoch=[1/100], Step=[62/2781], Loss=0.00070332, Avg_Acc: 0.02344\n",
            "TRAIN: Epoch=[1/100], Step=[63/2781], Loss=0.00089049, Avg_Acc: 0.00000\n",
            "TRAIN: Epoch=[1/100], Step=[64/2781], Loss=0.00072751, Avg_Acc: 0.00781\n",
            "TRAIN: Epoch=[1/100], Step=[65/2781], Loss=0.00077403, Avg_Acc: 0.03125\n",
            "TRAIN: Epoch=[1/100], Step=[66/2781], Loss=0.00096792, Avg_Acc: 0.00781\n",
            "TRAIN: Epoch=[1/100], Step=[67/2781], Loss=0.00079880, Avg_Acc: 0.03125\n",
            "TRAIN: Epoch=[1/100], Step=[68/2781], Loss=0.00077170, Avg_Acc: 0.01562\n",
            "TRAIN: Epoch=[1/100], Step=[69/2781], Loss=0.00086207, Avg_Acc: 0.03125\n",
            "TRAIN: Epoch=[1/100], Step=[70/2781], Loss=0.00077889, Avg_Acc: 0.00781\n",
            "TRAIN: Epoch=[1/100], Step=[71/2781], Loss=0.00090382, Avg_Acc: 0.03125\n",
            "TRAIN: Epoch=[1/100], Step=[72/2781], Loss=0.00070220, Avg_Acc: 0.00781\n",
            "TRAIN: Epoch=[1/100], Step=[73/2781], Loss=0.00072209, Avg_Acc: 0.07031\n",
            "TRAIN: Epoch=[1/100], Step=[74/2781], Loss=0.00079222, Avg_Acc: 0.01562\n",
            "TRAIN: Epoch=[1/100], Step=[75/2781], Loss=0.00084689, Avg_Acc: 0.00781\n",
            "TRAIN: Epoch=[1/100], Step=[76/2781], Loss=0.00075383, Avg_Acc: 0.01562\n",
            "TRAIN: Epoch=[1/100], Step=[77/2781], Loss=0.00075730, Avg_Acc: 0.01562\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}